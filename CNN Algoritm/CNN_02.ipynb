{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\geeth\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128)\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "DATA_DIR = r'C:\\Users\\geeth\\Downloads\\test_data\\YOLO-Object-Detection\\DL project\\Data'\n",
    "DEFECTIVE_DIR = os.path.join(DATA_DIR, 'Defective_cubes')\n",
    "QUALITY_DIR = os.path.join(DATA_DIR, 'Quality_cubes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label = 0 if directory == QUALITY_DIR else 1  # Assign label based on directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith('.jpg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "defective_images, defective_labels = load_data(DEFECTIVE_DIR)\n",
    "quality_images, quality_labels = load_data(QUALITY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_images = np.concatenate([defective_images, quality_images], axis=0)\n",
    "cube_labels = np.concatenate([defective_labels, quality_labels], axis=0)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(cube_images, cube_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_normalized = train_images / 255.0\n",
    "test_images_normalized = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    f1_score = 2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\geeth\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\geeth\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # Apply L2 regularization\n",
    "    tf.keras.layers.BatchNormalization(),  # Add BatchNormalization\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\geeth\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy','precision','recall','f1_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 51s 456ms/step - loss: 0.6622 - accuracy: 0.6720 - val_loss: 17.8671 - val_accuracy: 0.4894 - lr: 2.0000e-04\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 51s 456ms/step - loss: 0.6177 - accuracy: 0.6706 - val_loss: 16.1851 - val_accuracy: 0.4894 - lr: 2.0000e-04\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 50s 442ms/step - loss: 0.6113 - accuracy: 0.6762 - val_loss: 13.7117 - val_accuracy: 0.4905 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 50s 450ms/step - loss: 0.6066 - accuracy: 0.6868 - val_loss: 17.5876 - val_accuracy: 0.4905 - lr: 2.0000e-04\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 53s 469ms/step - loss: 0.6086 - accuracy: 0.6759 - val_loss: 4.4639 - val_accuracy: 0.6246 - lr: 2.0000e-04\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.6065 - accuracy: 0.6792 - val_loss: 68.2163 - val_accuracy: 0.4894 - lr: 2.0000e-04\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 51s 455ms/step - loss: 0.6033 - accuracy: 0.6787 - val_loss: 21.5518 - val_accuracy: 0.5140 - lr: 2.0000e-04\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 54s 479ms/step - loss: 0.6058 - accuracy: 0.6767 - val_loss: 46.0507 - val_accuracy: 0.4894 - lr: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24e13d72d70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(train_images_normalized, train_labels, batch_size=32),\n",
    "          epochs=10,  # Increase epochs for better training\n",
    "          validation_data=(test_images_normalized, test_labels),\n",
    "          callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 87ms/step - loss: 4.4639 - accuracy: 0.6246\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images_normalized, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
